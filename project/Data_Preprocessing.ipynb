{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook handles all the data preparation and storage needed for the analysis. We decided to separate the analysis into multiple notebooks in order to make the report more readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, constants and utilitary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Functions for reading and parsing files #####\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Functions related to the DataFrames directly #####\n",
    "\n",
    "def df_with_datetime(df, col_name='datetime', out_format=None):\n",
    "    if out_format:\n",
    "        df[col_name] = pd.to_datetime(df['unixReviewTime'], unit='s').dt.strftime(out_format)\n",
    "    else:\n",
    "        df[col_name] = pd.to_datetime(df['unixReviewTime'], unit='s')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection and storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first task is to task is to collect data from Amazon, organise this data and store it in a ready-to-use data format (pickes).\n",
    "\n",
    "To achieve this, we do the following:\n",
    "* Load the reviews data into dataframes\n",
    "* Load the products metadata into dataframes\n",
    "* Filter the reviews and products to only keep products considered \"healthy\"\n",
    "* Merge the metadata and the reviews into a single dataframe\n",
    "* Store the dataframe in the picke format\n",
    "\n",
    "We decided to restrict our analysis by choosing reviews and products from the **Grocery and Gourmet Food** and **Sports and Outdoors** categories as these categories are more representative of healthy lifestyle than the others.\n",
    "\n",
    "\n",
    "#### The Grocery and Gourmet Food category\n",
    "\n",
    "We see that the different categories in the 'Grocery & Gourmet Food' file are not directly useful, because:\n",
    "1. They are not directly telling us if the food is a healthy one or not\n",
    "2. We see that a lot of reviews are about products that are not in a category (except for the main one 'Grocery & Gourmet Food')\n",
    "    \n",
    "In order to get the reviews related to a healthy product in this file, we can try the following: we could read the title (and/or description) of all products in the metadata and find the ones containing some keyword related to a healthy lifestyle (e.g. \"organic\", \"natural\", ...). Once we have those products, we can keep only the reviews about those products (using the 'asin' value).\n",
    "\n",
    "#### The Sports and Outdoors category\n",
    "\n",
    "The Sports and Outdoors file contains categories that seem easy to categorize into healthy (or not), e.g. 'Exercise & Fitness' or 'Cycling', plus the products seem to be in more precise categories (not like in the 'Grocery & Gourmet Food' file). Thus, in order to get all reviews about products related to an healthy lifestyle, we could take all the reviews about a product that is in one of the 'healthy' categories, and we can choose those healthy categories manually.\n",
    "\n",
    "### Load the data into pandas dataframes\n",
    "\n",
    "Given the amount of data to treat, we do the computations sequentially (file by file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_TO_KEEP = ['asin', 'title', 'categories', 'price']\n",
    "REVIEWS_DATA_TO_KEEP = ['asin', 'overall', 'reviewText', 'datetime']\n",
    "HEALTHY_FOOD_KEYWORDS = ['organic', 'natural', 'sugar-free', 'healthy', 'vitamin',\n",
    "                        'supplement', 'minerals', 'diet', 'vegan']\n",
    "\n",
    "##### Functions related to the 'healthiness' of items #####\n",
    "\n",
    "def is_food_healthy(item):\n",
    "    for kw in HEALTHY_FOOD_KEYWORDS:\n",
    "        try:\n",
    "            if kw in item['title'].lower() or kw in item['description'].lower():\n",
    "                return True\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return False\n",
    "\n",
    "def is_sport_item_healthy(item):\n",
    "    for cat in get_categories(item):\n",
    "        if cat in HEALTHY_SPORT_CATEGORIES:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our utilitary functions ready, we can store the data into pickles. The created files are the following:\n",
    "* **food_reviews_df**: A file containing all the reviews of the Food category\n",
    "* **food_meta_df**: A file containing all the reviews of the Food category\n",
    "* **sports_reviews_df**: A file containing all the reviews of the Sports category\n",
    "* **sports_meta_df**: A file containing all the reviews of the Sports category\n",
    "* **healthy_food_df**: A file containing the merged information about healthy products and reviews of the Food category\n",
    "* **healthy_sports_df**: A file containing the merged information about healthy products and reviews of the Sports category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(filename, pickle_filename, with_datetime=False):\n",
    "    print('Saving file:', DATA_DIR + pickle_filename)\n",
    "\n",
    "    df = getDF(DATA_DIR + filename)\n",
    "    \n",
    "    if with_datetime:\n",
    "        df = df_with_datetime(df=df)\n",
    "    \n",
    "    df.to_pickle(DATA_DIR + pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file: data/sports_reviews_df\n"
     ]
    }
   ],
   "source": [
    "save_data('reviews_Grocery_and_Gourmet_Food.json.gz', 'food_reviews_df', True)\n",
    "save_data('meta_Grocery_and_Gourmet_Food.json.gz', 'food_meta_df')\n",
    "save_data('reviews_Sports_and_Outdoors.json.gz', 'sports_reviews_df', True)\n",
    "save_data('meta_Sports_and_Outdoors.json.gz', 'sports_meta_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_healthy_data(reviews_filename, metadata_filename, filtering_func, filename):\n",
    "    print('Retrieving data from pickles...')\n",
    "    reviews_df = pd.read_pickle(DATA_DIR + reviews_filename)\n",
    "    meta_df = pd.read_pickle(DATA_DIR + metadata_filename)\n",
    "\n",
    "    # Metadata about healthy products only\n",
    "    print('Filtering healthy products...')\n",
    "    meta_healthy_df = meta_df[meta_df.apply(lambda item: filtering_func(item), axis=1)]\n",
    "\n",
    "    # Reviews about healthy products merged with corresponding metadata\n",
    "    print('Merging dataframes...')\n",
    "    merged_healthy_df = pd.merge(meta_healthy_df[METADATA_TO_KEEP], reviews_df[REVIEWS_DATA_TO_KEEP], on='asin')\n",
    "\n",
    "    # Store file into a picke\n",
    "    print('Saving into pickle at:', DATA_DIR + filename)\n",
    "    merged_healthy_df.to_pickle(DATA_DIR + filename)\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_healthy_data(\n",
    "    'food_reviews_df',\n",
    "    'food_meta_df',\n",
    "    is_food_healthy,\n",
    "    'healthy_food_df'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_healthy_data(\n",
    "    'sports_reviews_df',\n",
    "    'sports_meta_df',\n",
    "    is_sport_item_healthy,\n",
    "    'healthy_sports_df'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
