{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the 200 top-ranking universities in www.topuniversities.com (ranking 2018). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the details page. Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "- Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "- Answer the previous question aggregating the data by (c) country and (d) region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation and assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "For this task, we have to retrieve the information in 2 separate steps.\n",
    "\n",
    "The first step is to retrieve the data (name of university, rank, country and region) using a simple GET query on a file. We used the Postman extension with the interceptor in order to find this file. The file contains a list of the 1000 best ranked universities sorted by rank. This file contains data in the JSON format.\n",
    "\n",
    "The second step is to retrieve the number of faculty members and the number of students (international and total) for each university by following the details page found in the JSON data. When reaching the details page, we can simply parse the HTML and retrieve the needed information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TOP_UNIVERSITIES_BASE = 'https://www.topuniversities.com'\n",
    "TOP_UNIVERSITIES_RANKING = TOP_UNIVERSITIES_BASE + '/sites/default/files/qs-rankings-data/357051.txt'\n",
    "column_names = ['name', 'rank_top', 'country', 'region', 'score']\n",
    "names_map = {\n",
    "    'total faculty':'faculty_tot',\n",
    "    'inter faculty': 'faculty_int',\n",
    "    'total student':'student_tot', \n",
    "    'total inter':'student_int'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = requests.get(TOP_UNIVERSITIES_RANKING)\n",
    "top_200 = ranking.json()['data'][0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities_top = pd.DataFrame(columns = (column_names + list(names_map.values())))\n",
    "\n",
    "def get_details_info(div_name):\n",
    "    div = soup.find('div',class_=div_name)\n",
    "    if div:\n",
    "        return int(div\n",
    "            .find('div',class_='number')\n",
    "            .text\n",
    "            .replace(\"\\n\",\"\")\n",
    "            .replace(\",\",\"\")\n",
    "            .strip())\n",
    "    else:\n",
    "        return float('NaN')\n",
    "\n",
    "for university in top_200:\n",
    "    row = {\n",
    "        'name': university['title'],\n",
    "        'rank_top': university['rank_display'],\n",
    "        'country': university['country'],\n",
    "        'region': university['region'],\n",
    "        'score': university['score']\n",
    "    }\n",
    "    \n",
    "    details_page_url = TOP_UNIVERSITIES_BASE + university['url']\n",
    "    r = requests.get(details_page_url)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    \n",
    "    for div_class, column_name in names_map.items():\n",
    "        row[column_name] = get_details_info(div_class)\n",
    "    \n",
    "    universities_top = universities.append(row, ignore_index=True)\n",
    "    \n",
    "universities_top.set_index(['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities_top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the 200 top-ranking universities in www.timeshighereducation.com (ranking 2018). Repeat the analysis of the previous point and discuss briefly what you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation and assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TIMES_BASE = 'https://www.timeshighereducation.com'\n",
    "TIMES_RANKING = TIMES_BASE + '/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json'\n",
    "column_names = ['name', 'rank_times', 'country', 'score']\n",
    "names_map = {\n",
    "    'total faculty':'faculty_tot',\n",
    "    'total student':'student_tot', \n",
    "    'total inter':'student_int'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = requests.get(TIMES_RANKING)\n",
    "top_200 = ranking.json()['data'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities_times = pd.DataFrame(columns = (column_names + list(names_map.values())))\n",
    "\n",
    "def to_int(value):\n",
    "    return int(value.replace(\",\",\"\").replace('%',\"\"))\n",
    "\n",
    "for university in top_200:\n",
    "    row = {\n",
    "        'name': university['name'],\n",
    "        'rank_times': university['rank'],\n",
    "        'country': university['location'],\n",
    "        'score': university['scores_overall'],\n",
    "        'faculty_tot': np.ceil(to_int(university['stats_number_students']) / float(university['stats_student_staff_ratio'])),   \n",
    "        'student_tot': university['stats_number_students'],   \n",
    "        'student_int': np.ceil(to_int(university['stats_number_students']) * (to_int(university['stats_pc_intl_students']) / 100)),   \n",
    "    }\n",
    "        \n",
    "    universities_times = universities.append(row, ignore_index=True)\n",
    "\n",
    "universities_times = universities_times.set_index(['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universities_times"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
